{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\rajeshkc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rajeshkc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "import nltk\n",
    "\n",
    "\n",
    "class Review:\n",
    "    def __init__(self, review_id: str, product_id: str, age: int, title: str, review_text: str, rating: int,\n",
    "                 recommends: bool, upvotes: int, division_name: str, department_name: str, class_name: str):\n",
    "        self.review_id = review_id\n",
    "        self.product_id = product_id\n",
    "        self.age = age\n",
    "        self.title = title\n",
    "        self.review_text = review_text\n",
    "        self.rating = rating\n",
    "        self.recommends = recommends\n",
    "        self.upvotes = upvotes\n",
    "        self.division_name = division_name\n",
    "        self.department_name = department_name\n",
    "        self.class_name = class_name\n",
    "\n",
    "    def full_text(self) -> str:\n",
    "        return f\"{self.title} {self.review_text}\"\n",
    "\n",
    "    def words(self) -> List[str]:\n",
    "        return nltk.word_tokenize(self.full_text())\n",
    "\n",
    "    def tagged_words(self) -> List[Tuple[str, str]]:\n",
    "        \"\"\" Returns each word in `full_text()` along with its predicted POS-tag. For instance, if `full_text()` is\n",
    "            \"I love this red shirt\", the returned list will be:\n",
    "            [('I', 'PRP'), ('love', 'VBP'), ('this', 'DT'), ('red', 'JJ'), ('shirt', 'NN')]\n",
    "            where each of the tags refer to a specific grammatical class.\n",
    "            See: https://pythonprogramming.net/natural-language-toolkit-nltk-part-speech-tagging/ for a list of all\n",
    "            possible tags\"\"\"\n",
    "        return nltk.pos_tag(self.words())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "import os\n",
    "\n",
    "from model.Review import Review\n",
    "\n",
    "\n",
    "data_dir = os.path.abspath(os.path.join(os.path.dirname(os.path.abspath(__file__)), os.pardir, \"data\"))\n",
    "\n",
    "def load_reviews() -> List[Review]:\n",
    "    print(\"Loading dataset ...\")\n",
    "    path = os.path.join(data_dir, \"reviews.csv\")\n",
    "    column_names = [\"review_id\", \"product_id\", \"age\", \"title\", \"review_text\", \"rating\", \"recommends\", \"upvotes\",\n",
    "                    \"division_name\", \"department_name\", \"class_name\"]\n",
    "    data = pd.read_csv(path, delimiter=\",\", names=column_names)\n",
    "    data.fillna(\"\")\n",
    "    dataset = []\n",
    "    for _, row in data.iterrows():\n",
    "        try:\n",
    "            entry = Review(str(row[\"review_id\"]), str(row[\"product_id\"]), int(row[\"age\"]), str(row[\"title\"]),\n",
    "                           str(row[\"review_text\"]), int(row[\"rating\"]), bool(int(row[\"recommends\"])),\n",
    "                           int(row[\"upvotes\"]), str(row[\"division_name\"]), str(row[\"department_name\"]), str(row[\"class_name\"]))\n",
    "            dataset.append(entry)\n",
    "        except:\n",
    "            pass\n",
    "    print(f\"Dataset loaded ({len(dataset)} rows).\")\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
