{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rajeshkc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\rajeshkc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rajeshkc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "def convert_tag(tag):\n",
    "    \"\"\"Convert the tag given by nltk.pos_tag to the tag used by wordnet.synsets\"\"\"\n",
    "    \n",
    "    tag_dict = {'N': 'n', 'J': 'a', 'R': 'r', 'V': 'v'}\n",
    "    try:\n",
    "        return tag_dict[tag[0]]\n",
    "    except KeyError:\n",
    "        return None\n",
    "doc='Fish are nvqjp friends.'\n",
    "\n",
    "def doc_to_synsets(doc):\n",
    "    \"\"\"\n",
    "    Returns a list of synsets in document.\n",
    "\n",
    "    Tokenizes and tags the words in the document doc.\n",
    "    Then finds the first synset for each word/tag combination.\n",
    "    If a synset is not found for that combination it is skipped.\n",
    "\n",
    "    Args:\n",
    "        doc: string to be converted\n",
    "\n",
    "    Returns:\n",
    "        list of synsets\n",
    "\n",
    "    Example:\n",
    "        doc_to_synsets('Fish are nvqjp friends.')\n",
    "        Out: [Synset('fish.n.01'), Synset('be.v.01'), Synset('friend.n.01')]\n",
    "    \"\"\"\n",
    "    token= nltk.word_tokenize(doc)\n",
    "    tokens1 = [WordNetLemmatizer().lemmatize(t) for t in token]\n",
    "    postag=nltk.pos_tag(tokens1)\n",
    "    word_converted_tag = [(i[0],convert_tag(i[1])) for i in postag]\n",
    "    out=[wn.synsets(w) for w,i in  word_converted_tag]\n",
    "    wn_tag=[]\n",
    "    \n",
    "    for w, i in word_converted_tag:\n",
    "        if len(wn.synsets(w))>1 and i=='n':\n",
    "            wn_tag.append(wn.synsets(w)[0])\n",
    "        if len(wn.synsets(w))>1 and i=='v':\n",
    "            wn_tag.append(wn.synsets(w)[1])\n",
    "                \n",
    "            \n",
    "            \n",
    "    #wn_tag=[]\n",
    "    #tag=([tag for (token,tag) in postag])\n",
    "    #for i in tag:\n",
    "     #   if i.startswith('J'):\n",
    "      #      wn_tag.append('a')\n",
    "       # if i.startswith('N'):\n",
    "        #    wn_tag.append('n')\n",
    "        #if i.startswith('R'):\n",
    "         #   wn_tag.append('r')\n",
    "        #if i.startswith('V'):\n",
    "        #    wn_tag.append('v')\n",
    "            \n",
    "   # if tag.upper().startswith('J'):\n",
    "    #    wn_tag.append('a')\n",
    "    #elif tag.startswith('N'):\n",
    "    #    wn_tag.append('n')\n",
    "    #elif tag.startswith('R'):\n",
    "     #   wn_tag.append('r')\n",
    "    #elif tag.startswith('V'):\n",
    "    #    wn_tag.append('v')\n",
    "    #out=[wn.synsets(w) for w in token]\n",
    "    #if any([l.startswith(s) for s in x])\n",
    "    #pass\n",
    "    #print(out)\n",
    "    #for i in tag:\n",
    "     #   for a in out[0]:\n",
    "      #      if a.pos()== 'tag[i]':\n",
    "       #         syn=a\n",
    "        #if b.pos()=='v':\n",
    "         #   synst1=b\n",
    "        #if c.pos()=='n':\n",
    "          #  synst2=c\n",
    "    #sysn=[synst,synst1,synst2]\n",
    "  \n",
    "    #word_converted_tag = [(i[0],convert_tag(i[1])) for i in postag]\n",
    "    #out=[wn.synsets(w)\n",
    "    #sys=[]\n",
    "    #for i in range(0,len(word_converted_tag)):\n",
    "        #if i=='n':\n",
    "         #   sys.append(wn.synsets(w))\n",
    "            \n",
    "     #   if word_converted_tag[i].pos()=='n':\n",
    "      #      sys.append(word_converted_tag[i])\n",
    "        #if i=='v':\n",
    "            #sys1=wn.synsets(w)\n",
    "        \n",
    "         \n",
    "         \n",
    "            \n",
    "\n",
    "    # Your Code Here\n",
    "    \n",
    "    return wn_tag #wn.synsets(fish)[0],wn.synsets(fish)[1], wn_tag,out#sys#word_converted_tag,sys,sys1,out#word_converted_tag#syn #print(postag)# Your Answer Here\n",
    "\n",
    "#print(doc_to_synsets(Fish are nvqjp friends.))\n",
    "#print(doc_to_synsets('Fish are nvqjp friends.'))\n",
    "#def similarity_score(s1, s2):\n",
    "#synsets1 = doc_to_synsets('I like cats')\n",
    "#synsets2 = doc_to_synsets('I like dogs')\n",
    "#similarity_score(synsets1, synsets2)\n",
    "    \n",
    "    # Your Code Here\n",
    "    \n",
    "#    return print(similarity_score(synsets1, synsets2))\n",
    "#similarity_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc_to_synsets('I like dogs and cats mouth be or iodine syringe friends fishes to'))\n",
    "print(doc_to_synsets('Fish are nvqjp friends.'))\n",
    "s1 = doc_to_synsets('I like cats')\n",
    "s2 = doc_to_synsets('I like dogs')\n",
    "\n",
    "\n",
    "#def similarity_score():\n",
    "similarity_score=[]\n",
    "#wn.synset(w1).wup_similarity(wn.synset(w2)) \n",
    "for w1 in s1:\n",
    "    for w2 in s2:\n",
    "        similarity_score.append(wn.synset(w1.lower()).wup_similarity(wn.synset(w2.lower())))\n",
    "print(similarity_score)\n",
    "    \n",
    "\n",
    "s1 = doc_to_synsets('I like cats')\n",
    "s2 = doc_to_synsets('I like dogs')\n",
    "def similarity_score(s11, s22):\n",
    "    my_list = {}\n",
    "    for w1 in s1:\n",
    "        value = max(wn.path_similarity(w1, w2) for w2 in s22)\n",
    "        my_list[w1] = value\n",
    "        #np.array([my_list[k] for k in my_list]).mean()\n",
    "    return  my_list\n",
    "print (similarity_score(s1, s2))\n",
    "\n",
    "\n",
    "score = []\n",
    "for i in synset1:    \n",
    "    for j in synset2:        \n",
    "        score.append(\"\"\"scoreing function for i on j \"\"\")    \n",
    "    maxScore.append(max(score)) \n",
    "normalized = sum(maxScore)/len(maxScore)\n",
    "#np.mean([x[2] for x in my_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_list = []\n",
    "def similarity_score(s1, s2):\n",
    "    for word1 in s1:\n",
    "        best = max(wn.path_similarity(word1, word2) for word2 in s2)\n",
    "        ps_list.append(best)\n",
    "    return ps_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = 'This is a function to test document_path_similarity.'\n",
    "doc2 = 'Use this function to see if your code in doc_to_synsets \\and similarity_score is correct!'\n",
    "\n",
    "def document_path_similarity(doc1, doc2):\n",
    "    \"\"\"Finds the symmetrical similarity between doc1 and doc2\"\"\"\n",
    "\n",
    "    synsets1 = doc_to_synsets(doc1)\n",
    "    synsets2 = doc_to_synsets(doc2)\n",
    "\n",
    "    return (similarity_score(synsets1, synsets2) + similarity_score(synsets2, synsets1)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
